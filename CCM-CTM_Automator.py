import pandas as pd
import time
import google.generativeai as genai
from tqdm import tqdm
import re
import sys
import os

# ğŸ” Gemini API Setup
try:
    genai.configure(api_key="AIzaSyDQItObHG6C80KP1-0-ZyaGZehcvHPN4tY")
    model = genai.GenerativeModel("gemini-2.5-flash-lite-preview-06-17")

    # ğŸ” Test Gemini initialization
    test = model.generate_content("Say OK").text.strip()
    if "OK" not in test:
        raise RuntimeError("Gemini model responded but not as expected.")
    print("âœ… Gemini is successfully initialized and responding.")

except Exception as e:
    print(f"âŒ Failed to initialize Gemini model: {e}")
    sys.exit(1)

# âœï¸ Target company BD
target_bd = """
"ABC is a global merchant and processor of agricultural goods. It's a leading company in the agricultural sector, sourcing, transporting, and transforming products for customers worldwide. It operates across various business lines, including Coffee, Cotton, Freight, Food & Feed Solutions, Grains & Oilseeds, Juice, Rice, and Sugar. The company has a significant presence in India "
"""

# ğŸ“‚ Load Excel
df = pd.read_excel("BD_EV.xlsx")  # Must have "Company Name" and "Business Description"

# Debug: Print column names and first few rows
print("ğŸ“Š Excel file columns:", df.columns.tolist())
print("ğŸ“Š First 3 rows of data:")
print(df.head(3))

# ğŸ—‚ï¸ Output setup
output_file = "matched_comparables.xlsx"
results = []
chunk_count = 0  # To track and name chunks

# ğŸ” Loop through each company
for idx, row in tqdm(df.iterrows(), total=len(df), desc="ğŸ” Matching Companies"):

    comp_name = row["Company Name"]
    comp_bd = row["Business Description"]

    # Debug: Print current company info
    print(f"\nğŸ” Processing: {comp_name}")
    print(f"ğŸ“ BD Preview: {str(comp_bd)[:100]}..." if pd.notna(comp_bd) else "ğŸ“ BD: [BLANK/NaN]")

    # Handle NaN or empty business descriptions
    if pd.isna(comp_bd) or comp_bd == "" or str(comp_bd).strip() == "":
        comp_bd = "No business description available"
        print(f"âš ï¸ Warning: Empty BD for {comp_name}, using default text")

    # ğŸ” Prompt with score + explanation
    prompt = f"""
You are an equity research analyst evaluating potential acquisition targets for Louis Dreyfus, which is looking to expand it's operations into edible oils.

The objective is to acquire a company that operates in one or more of the following:
- Processing/refining of edible oils (e.g., palm, soybean, sunflower, mustard, groundnut)
- Bulk or packaged oil distribution (domestic or export markets)
- Crude oil import and refining infrastructure
- Contract manufacturing or white-label edible oil brands
- Integrated value chain: from oilseed crushing to packaging and B2B/B2C distribution

{target_bd}

Comparable Company: {comp_name}
Comparable Company Description:
{comp_bd}

Instructions:
1. Use your internal understanding and search capability to verify the comparable company.
2. Give a similarity score from 0% to 100% with decimal precision (e.g., 91.35%).
3. After the score, write a short 1â€“2 line reason explaining why you gave that score.
4. Return 0 if you can't find a match and give reason.
4. Format your response like this:
91.35%

"""

    score = "Error"
    reason = ""
    retries = 0
    max_retries = 3

    while retries < max_retries:
        try:
            response = model.generate_content(prompt)
            full_response = response.text.strip()

            # ğŸ“¢ Print Gemini's full response for debugging
            print(f"\nğŸ¤– Gemini Response for {comp_name}:")
            print("=" * 80)
            print(full_response)
            print("=" * 80)

            # âœ… Try to extract a % score using regex
            match = re.search(r"(\d{1,3}(?:\.\d+)?)[ ]?%", full_response)
            if match:
                score = round(float(match.group(1)), 2)
                reason = full_response[match.end():].strip()
                print(f"âœ… Extracted Score: {score}%")
                print(f"âœ… Extracted Reason: {reason}")
            else:
                score = 0.00
                reason = "No valid score found, defaulted to 0.00%."
                print(f"âš ï¸ No score pattern found in response, defaulting to 0.00%")
            break

        except Exception as e:
            retries += 1
            print(f"âš ï¸ Error with {comp_name} (attempt {retries}/3): {e}")
            time.sleep(10)

    # Store results with explicit handling of BD
    result_entry = {
        "Company Name": str(comp_name) if pd.notna(comp_name) else "Unknown",
        "Business Description": str(comp_bd) if pd.notna(comp_bd) else "No description available",
        "Similarity Score (%)": score if score != "Error" else "Error",
        "Reason for Score": reason if score != "Error" else "N/A"
    }

    results.append(result_entry)

    # Debug: Print what we're storing
    print(f"ğŸ’¾ Storing BD: {result_entry['Business Description'][:50]}...")

    # ğŸ’¾ Save chunk after every 10 rows
    if (idx + 1) % 10 == 0 or idx == len(df) - 1:
        chunk_count += 1
        chunk_file = f"matched_chunk_{chunk_count}.xlsx"
        chunk_df = pd.DataFrame(results)

        # Debug: Print chunk info before saving
        print(f"ğŸ“Š Chunk {chunk_count} has {len(chunk_df)} rows")
        if len(chunk_df) > 0:
            sample_bd = chunk_df.iloc[0]['Business Description']
            if pd.notna(sample_bd):
                print(f"ğŸ“Š Sample BD from chunk: {str(sample_bd)[:50]}...")
            else:
                print("ğŸ“Š Sample BD from chunk: [NaN/Empty]")

        chunk_df.to_excel(chunk_file, index=False)
        print(f"ğŸ’¾ Saved chunk: {chunk_file}")
        results = []  # Clear the chunk list

        # â±ï¸ Wait after chunk save
        print("â±ï¸ Waiting 5 seconds after saving chunk...")
        time.sleep(5)

    # ğŸ•’ Sleep after each company
    time.sleep(1)

# ğŸ§© Combine all chunks into final output
print("ğŸ“¦ Combining all chunks into final output...")
chunk_files = [f for f in os.listdir() if f.startswith("matched_chunk_") and f.endswith(".xlsx")]
if chunk_files:
    combined_df = pd.concat([pd.read_excel(f) for f in chunk_files], ignore_index=True)

    # Debug: Check final combined data
    print(f"ğŸ“Š Final combined data has {len(combined_df)} rows")
    print(f"ğŸ“Š Columns: {combined_df.columns.tolist()}")

    # Safe way to check sample BD (handle potential NaN/float values)
    if len(combined_df) > 0:
        sample_bd = combined_df.iloc[0]['Business Description']
        if pd.notna(sample_bd):
            print(f"ğŸ“Š Sample final BD: {str(sample_bd)[:50]}...")
        else:
            print("ğŸ“Š Sample final BD: [NaN/Empty]")

    # Clean up any remaining NaN values before saving
    combined_df['Business Description'] = combined_df['Business Description'].fillna("No description available")

    combined_df.to_excel(output_file, index=False)
    print(f"âœ… Done. Final file saved: {output_file}")
else:
    print("âš ï¸ No chunk files found to combine!")

# ğŸ§¹ Clean up chunk files
for f in chunk_files:
    try:
        os.remove(f)
        print(f"ğŸ—‘ï¸ Deleted chunk file: {f}")
    except Exception as e:
        print(f"âš ï¸ Could not delete {f}: {e}")
